{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ti2E9BmCArOBakWHEduad5GeN4J1dnYU",
      "authorship_tag": "ABX9TyPgyPPbccJYybHWFPDE7IfL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Burgunthy/Tensorflow2_Practice/blob/main/tf2-10-5-mnist_nn_dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT8rOGI_CtYu"
      },
      "source": [
        "# MNist를 사용하여 실습 진행\n",
        "# softmax를 이용하여 output 구함\n",
        "# layer의 크기를 바꿔가며 가장 효율적인 모델 구축 -> drop out 사용\n",
        "# loss: 0.0154 - accuracy: 0.9954\n",
        "# 거의 비슷한 결과를 냈다. 다른 dataset에서도 사용해 효율을 분석한다\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kv7PfSuCuU3"
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "# 한번에 100 개의 dataset 씩 학습\n",
        "training_epochs = 15\n",
        "# 15번의 training\n",
        "nb_classes = 10\n",
        "# 마지막 softmax 출력 값\n",
        "\n",
        "drop_rate = 0.3\n",
        "# drop out 함수 추가"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gXI1SOUCwWg",
        "outputId": "445b82c2-7933-4217-ee1f-2e175f405f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "# keras를 통해 mnist 파일 불러오기\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# MNist data load. -> 추후 개인 공부에도 사용\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "# 픽셀을 255로 나눠 0 ~ 1 사이의 값으로 normalization\n",
        "\n",
        "print(x_train.shape)  # (60000, 28, 28)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
        "print(x_train.shape) # (60000, 784)\n",
        "# 쉬운 학습을 위해 3차원 -> 2차원 변환\n",
        "# * 을 사용하여 위와 같이 일렬로 만들 수 있다\n",
        "\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "# in tf1, one_hot= True in read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "# 직접 one_hot encoding하여 train, test의 결과값을 저장한다"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W2VbvfpCzTG",
        "outputId": "1faab370-15cb-4f94-9cd2-c7e692e69ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Xavier 정규분포 초기값 설정\n",
        "# stddev = sqrt(2 / (fan_in + fan_out))\n",
        "\n",
        "tf.model = tf.keras.Sequential()\n",
        "tf.model.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
        "\n",
        "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
        "\n",
        "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
        "\n",
        "tf.model.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "tf.model.add(tf.keras.layers.Dropout(drop_rate))\n",
        "\n",
        "tf.model.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
        "# one_hot을 위해 해당 loss 사용\n",
        "\n",
        "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "tf.model.summary()\n",
        "\n",
        "history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)\n",
        "# batch와 epoch을 이와 같이 활용하니 더욱 깔끔하다.\n",
        "# pytorch보다 괜찮고 깔끔하게 사용 가능"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,195,018\n",
            "Trainable params: 1,195,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3168 - accuracy: 0.9011\n",
            "Epoch 2/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1479 - accuracy: 0.9570\n",
            "Epoch 3/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1165 - accuracy: 0.9666\n",
            "Epoch 4/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0961 - accuracy: 0.9719\n",
            "Epoch 5/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0814 - accuracy: 0.9768\n",
            "Epoch 6/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0767 - accuracy: 0.9768\n",
            "Epoch 7/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0670 - accuracy: 0.9797\n",
            "Epoch 8/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0640 - accuracy: 0.9807\n",
            "Epoch 9/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0589 - accuracy: 0.9827\n",
            "Epoch 10/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0556 - accuracy: 0.9827\n",
            "Epoch 11/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0519 - accuracy: 0.9850\n",
            "Epoch 12/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0486 - accuracy: 0.9860\n",
            "Epoch 13/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0481 - accuracy: 0.9858\n",
            "Epoch 14/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0450 - accuracy: 0.9870\n",
            "Epoch 15/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0416 - accuracy: 0.9877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiEHPmthC5Y-",
        "outputId": "b1d29992-5296-4b54-c9ec-e69b783162d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "predictions = tf.model.predict(x_test)\n",
        "print('Prediction: \\n', predictions)\n",
        "\n",
        "score = tf.model.evaluate(x_train, y_train)\n",
        "print('Accuracy: ', score[1])\n",
        "# loss: 0.2455 - accuracy: 0.9320"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: \n",
            " [[4.4343102e-15 3.2559275e-11 1.0330937e-12 ... 9.9999988e-01\n",
            "  4.3541224e-14 1.7626786e-07]\n",
            " [1.0252072e-11 2.8008594e-11 9.9999988e-01 ... 2.4638798e-11\n",
            "  7.1242690e-10 9.0981899e-13]\n",
            " [3.4426372e-20 1.0000000e+00 2.4116841e-15 ... 1.4349799e-11\n",
            "  1.9597211e-11 1.1621773e-15]\n",
            " ...\n",
            " [3.0117224e-15 1.0116582e-11 8.0101708e-13 ... 1.4356565e-10\n",
            "  3.8268512e-12 2.1129176e-07]\n",
            " [2.4832565e-26 4.1415108e-26 2.9863789e-25 ... 1.0797138e-27\n",
            "  9.0497209e-19 1.4017469e-22]\n",
            " [5.1816468e-12 2.1065995e-13 1.5296844e-14 ... 4.1310555e-21\n",
            "  8.6557463e-14 2.1909420e-14]]\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0154 - accuracy: 0.9954\n",
            "Accuracy:  0.9954000115394592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfvK8_e8Hq0K",
        "outputId": "b78efea3-e714-44d7-a5f0-c430e941cb4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# test 하는 함수\n",
        "random.seed(777)\n",
        "\n",
        "y_predicted = tf.model.predict(x_test)\n",
        "# x_test를 통해 미리 predict된 list 생성\n",
        "for x in range(0, 10):\n",
        "    random_index = random.randint(0, x_test.shape[0]-1)\n",
        "    # x_test의 크기 중 random index를 구한다.\n",
        "    \n",
        "    print(\"index: \", random_index,\n",
        "          \"actual y: \", np.argmax(y_test[random_index]),\n",
        "          \"predicted y: \", np.argmax(y_predicted[random_index]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index:  3757 actual y:  8 predicted y:  8\n",
            "index:  7304 actual y:  5 predicted y:  5\n",
            "index:  7300 actual y:  7 predicted y:  7\n",
            "index:  6039 actual y:  9 predicted y:  9\n",
            "index:  9429 actual y:  3 predicted y:  3\n",
            "index:  4420 actual y:  5 predicted y:  5\n",
            "index:  5507 actual y:  2 predicted y:  2\n",
            "index:  8809 actual y:  1 predicted y:  1\n",
            "index:  654 actual y:  5 predicted y:  5\n",
            "index:  7302 actual y:  8 predicted y:  8\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}