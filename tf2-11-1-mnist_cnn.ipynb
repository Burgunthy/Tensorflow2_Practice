{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ti2E9BmCArOBakWHEduad5GeN4J1dnYU",
      "authorship_tag": "ABX9TyMbZZmbfOioqu1asJYxdYFF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Burgunthy/Tensorflow2_Practice/blob/main/tf2-11-1-mnist_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT8rOGI_CtYu"
      },
      "source": [
        "# MNist를 사용하여 실습 진행\n",
        "# softmax를 이용하여 output 구함\n",
        "# layer의 크기를 바꿔가며 가장 효율적인 모델 구축 -> conv2d 사용\n",
        "# loss: 0.0112 - accuracy: 0.9969\n",
        "# 지금까지는 최고의 효율 출력\n",
        "# 해당 공부를 통해 추후 UNET 등 tf2로 구현 가능\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kv7PfSuCuU3"
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "# 한번에 100 개의 dataset 씩 학습\n",
        "training_epochs = 15\n",
        "# 15번의 training\n",
        "nb_classes = 10\n",
        "# 마지막 softmax 출력 값\n",
        "\n",
        "drop_rate = 0.3\n",
        "# drop out 함수 추가"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gXI1SOUCwWg",
        "outputId": "c6cda1f6-43c4-4d8f-a255-266f5fe32cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "# keras를 통해 mnist 파일 불러오기\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# MNist data load. -> 추후 개인 공부에도 사용\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "# 픽셀을 255로 나눠 0 ~ 1 사이의 값으로 normalization\n",
        "\n",
        "print(x_train.shape)  # (60000, 28, 28)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "# 이미지 자체를 입력하기 위해 채널을 추가해 28 * 28 * 1 로 reshape한다.\n",
        "\n",
        "print(x_train.shape)\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "# in tf1, one_hot= True in read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "# 직접 one_hot encoding하여 train, test의 결과값을 저장한다"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W2VbvfpCzTG",
        "outputId": "43795496-fbff-425f-9fda-eb3238d4094b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "tf.model = tf.keras.Sequential()\n",
        "# 아래와 같은 선언에 익숙해져야 한다\n",
        "\n",
        "tf.model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
        "tf.model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# L1 : CONV, POOL\n",
        "# 16개의 필터를 사용한다. kernel size : 3 x 3\n",
        "\n",
        "tf.model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "tf.model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# L2\n",
        "# 32개의 필터를 사용한다. kernel size : 3 x 3\n",
        "\n",
        "tf.model.add(tf.keras.layers.Flatten())\n",
        "tf.model.add(tf.keras.layers.Dense(units=10, kernel_initializer='glorot_normal', activation='softmax'))\n",
        "# L3 fully connected -> 모든 수를 일자로 만들어 10 output_shape의 softmax를 진행한다\n",
        "\n",
        "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "tf.model.summary()\n",
        "\n",
        "history =  tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                8010      \n",
            "=================================================================\n",
            "Total params: 12,810\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3024 - accuracy: 0.9178\n",
            "Epoch 2/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0864 - accuracy: 0.9737\n",
            "Epoch 3/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0644 - accuracy: 0.9805\n",
            "Epoch 4/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0534 - accuracy: 0.9838\n",
            "Epoch 5/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0462 - accuracy: 0.9858\n",
            "Epoch 6/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0409 - accuracy: 0.9872\n",
            "Epoch 7/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0370 - accuracy: 0.9882\n",
            "Epoch 8/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0332 - accuracy: 0.9900\n",
            "Epoch 9/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0299 - accuracy: 0.9906\n",
            "Epoch 10/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0270 - accuracy: 0.9915\n",
            "Epoch 11/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0252 - accuracy: 0.9919\n",
            "Epoch 12/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0227 - accuracy: 0.9927\n",
            "Epoch 13/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0209 - accuracy: 0.9933\n",
            "Epoch 14/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0184 - accuracy: 0.9942\n",
            "Epoch 15/15\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0166 - accuracy: 0.9950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiEHPmthC5Y-",
        "outputId": "9a45cc98-e604-4811-f961-218b5c849fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "predictions = tf.model.predict(x_test)\n",
        "print('Prediction: \\n', predictions)\n",
        "\n",
        "score = tf.model.evaluate(x_train, y_train)\n",
        "print('Accuracy: ', score[1])\n",
        "# loss: 0.2455 - accuracy: 0.9320"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: \n",
            " [[7.0002421e-11 1.7072654e-09 8.3643738e-07 ... 9.9998355e-01\n",
            "  2.5295257e-09 2.4048560e-07]\n",
            " [3.5516818e-09 1.0456401e-06 9.9999845e-01 ... 2.2816225e-11\n",
            "  1.9648795e-07 3.4865336e-14]\n",
            " [1.8259490e-08 9.9988139e-01 3.9078823e-06 ... 3.0907951e-05\n",
            "  7.6107840e-06 1.5827631e-07]\n",
            " ...\n",
            " [9.2958258e-13 1.9480494e-10 4.1317693e-13 ... 1.2233644e-07\n",
            "  8.5813312e-08 1.6527505e-08]\n",
            " [2.3603977e-09 2.4970385e-15 1.3366920e-13 ... 4.8116693e-12\n",
            "  2.1896930e-04 2.3106311e-10]\n",
            " [3.7317091e-10 7.7527367e-15 4.5774060e-09 ... 2.9328334e-12\n",
            "  4.0867754e-08 2.2500491e-13]]\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0120 - accuracy: 0.9968\n",
            "Accuracy:  0.9967666864395142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfvK8_e8Hq0K",
        "outputId": "f506240c-23a4-4273-e877-daaa7f770f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# test 하는 함수\n",
        "random.seed(777)\n",
        "\n",
        "y_predicted = tf.model.predict(x_test)\n",
        "# x_test를 통해 미리 predict된 list 생성\n",
        "for x in range(0, 10):\n",
        "    random_index = random.randint(0, x_test.shape[0]-1)\n",
        "    # x_test의 크기 중 random index를 구한다.\n",
        "    \n",
        "    print(\"index: \", random_index,\n",
        "          \"actual y: \", np.argmax(y_test[random_index]),\n",
        "          \"predicted y: \", np.argmax(y_predicted[random_index]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index:  3757 actual y:  8 predicted y:  8\n",
            "index:  7304 actual y:  5 predicted y:  5\n",
            "index:  7300 actual y:  7 predicted y:  7\n",
            "index:  6039 actual y:  9 predicted y:  9\n",
            "index:  9429 actual y:  3 predicted y:  3\n",
            "index:  4420 actual y:  5 predicted y:  5\n",
            "index:  5507 actual y:  2 predicted y:  2\n",
            "index:  8809 actual y:  1 predicted y:  1\n",
            "index:  654 actual y:  5 predicted y:  5\n",
            "index:  7302 actual y:  8 predicted y:  8\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}