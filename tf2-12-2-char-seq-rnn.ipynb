{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlRc/r7UegQH825tq0T1XD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Burgunthy/Tensorflow2_Practice/blob/main/tf2-12-2-char-seq-rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA9U4v1bPx8u"
      },
      "source": [
        "# Lab 12 Character Sequence RNN\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDKAmSDoP2DV"
      },
      "source": [
        "sample = \" if you want you\"\n",
        "idx2char = list(set(sample))  # index -> char\n",
        "char2idx = {c: i for i, c in enumerate(idx2char)}  # char -> idex\n",
        "\n",
        "# hyper parameters\n",
        "dic_size = len(char2idx)  # RNN input size (one hot size)\n",
        "hidden_size = len(char2idx)  # RNN output size\n",
        "num_classes = len(char2idx)  # final output size (RNN or softmax, etc.)\n",
        "batch_size = 1  # one sample data, one batch\n",
        "sequence_length = len(sample) - 1  # number of lstm rollings (unit #)\n",
        "learning_rate = 0.1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWTHKAiDP2Hk"
      },
      "source": [
        "sample_idx = [char2idx[c] for c in sample]  # char to index\n",
        "x_data = [sample_idx[:-1]]  # X data sample (0 ~ n-1) hello: hell\n",
        "y_data = [sample_idx[1:]]   # Y label sample (1 ~ n) hello: ello\n",
        "\n",
        "x_one_hot_eager = tf.one_hot(x_data, num_classes)  # one hot: 1 -> 0 1 0 0 0 0 0 0 0 0\n",
        "x_one_hot_numpy = tf.keras.utils.to_categorical(x_data, num_classes)  # it'll generate numpy array, either way works\n",
        "y_one_hot_eager = tf.one_hot(y_data, num_classes)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TloFZjhxP8lk",
        "outputId": "b7ca5296-6d91-4d45-e2d0-590f1975f002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.model = tf.keras.Sequential();\n",
        "tf.model.add(tf.keras.layers.\n",
        "             LSTM(units=num_classes, input_shape=(sequence_length, x_one_hot_eager.shape[2]), return_sequences=True))\n",
        "tf.model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation='softmax')))\n",
        "tf.model.summary()\n",
        "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "                 metrics=['accuracy'])\n",
        "tf.model.fit(x_one_hot_eager, y_one_hot_eager, epochs=50)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 15, 10)            840       \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 15, 10)            110       \n",
            "=================================================================\n",
            "Total params: 950\n",
            "Trainable params: 950\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2900 - accuracy: 0.1333\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1339 - accuracy: 0.1333\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9652 - accuracy: 0.4667\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7506 - accuracy: 0.4000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5062 - accuracy: 0.6000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2234 - accuracy: 0.8000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.9550 - accuracy: 0.8667\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7517 - accuracy: 0.8667\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.9333\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.9333\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.9333\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9333\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.5220e-04 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9094e-04 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3694e-04 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.8925e-04 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4704e-04 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0955e-04 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.7621e-04 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4646e-04 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.1986e-04 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9600e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f831e6c8780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xup2gERHP-j0",
        "outputId": "d3e44a37-4a50-4c4e-b0ea-c279c3f229b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predictions = tf.model.predict(x_one_hot_eager)\n",
        "\n",
        "for i, prediction in enumerate(predictions):\n",
        "    # print char using argmax, dict\n",
        "    result_str = [idx2char[c] for c in np.argmax(prediction, axis=1)]\n",
        "    print(\"\\tPrediction str: \", ''.join(result_str))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tPrediction str:  if you want you\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}