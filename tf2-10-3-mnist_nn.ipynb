{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ti2E9BmCArOBakWHEduad5GeN4J1dnYU",
      "authorship_tag": "ABX9TyNF9AfIUbmevaw4CVjGC3TH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Burgunthy/Tensorflow2_Practice/blob/main/tf2-10-3-mnist_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT8rOGI_CtYu"
      },
      "source": [
        "# MNist를 사용하여 실습 진행\n",
        "# softmax를 이용하여 output 구함\n",
        "# layer의 크기를 바꿔가며 가장 효율적인 모델 구축 -> 784 -> 256 -> 10\n",
        "# loss: 0.0063 - accuracy: 0.9984\n",
        "# 간단하지만 매우 높은 효율!\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kv7PfSuCuU3"
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "# 한번에 100 개의 dataset 씩 학습\n",
        "training_epochs = 15\n",
        "# 15번의 training\n",
        "nb_classes = 10\n",
        "# 마지막 softmax 출력 값"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gXI1SOUCwWg",
        "outputId": "525577f8-a748-41e0-8d79-a52d23b06e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "# keras를 통해 mnist 파일 불러오기\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# MNist data load. -> 추후 개인 공부에도 사용\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "# 픽셀을 255로 나눠 0 ~ 1 사이의 값으로 normalization\n",
        "\n",
        "print(x_train.shape)  # (60000, 28, 28)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
        "print(x_train.shape) # (60000, 784)\n",
        "# 쉬운 학습을 위해 3차원 -> 2차원 변환\n",
        "# * 을 사용하여 위와 같이 일렬로 만들 수 있다\n",
        "\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "# in tf1, one_hot= True in read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "# 직접 one_hot encoding하여 train, test의 결과값을 저장한다"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W2VbvfpCzTG",
        "outputId": "652b9da7-91db-4079-b401-27d36f48a696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "tf.model = tf.keras.Sequential()\n",
        "tf.model.add(tf.keras.layers.Dense(input_dim=784, units=256, activation='relu'))\n",
        "tf.model.add(tf.keras.layers.Dense(input_dim=256, units=nb_classes, activation='softmax'))\n",
        "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adam(0.001), metrics=['accuracy'])\n",
        "# one_hot을 위해 해당 loss 사용\n",
        "tf.model.summary()\n",
        "\n",
        "history = tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)\n",
        "# batch와 epoch을 이와 같이 활용하니 더욱 깔끔하다.\n",
        "# pytorch보다 괜찮고 깔끔하게 사용 가능"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.2862 - accuracy: 0.9200\n",
            "Epoch 2/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1219 - accuracy: 0.9649\n",
            "Epoch 3/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.9756\n",
            "Epoch 4/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.9818\n",
            "Epoch 5/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0465 - accuracy: 0.9863\n",
            "Epoch 6/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0361 - accuracy: 0.9894\n",
            "Epoch 7/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9919\n",
            "Epoch 8/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9941\n",
            "Epoch 9/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0172 - accuracy: 0.9955\n",
            "Epoch 10/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0139 - accuracy: 0.9966\n",
            "Epoch 11/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0113 - accuracy: 0.9971\n",
            "Epoch 12/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0086 - accuracy: 0.9981\n",
            "Epoch 13/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9977\n",
            "Epoch 14/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0067 - accuracy: 0.9985\n",
            "Epoch 15/15\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiEHPmthC5Y-",
        "outputId": "b458631d-aa32-4b27-9b7f-ebc9db087e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "predictions = tf.model.predict(x_test)\n",
        "print('Prediction: \\n', predictions)\n",
        "\n",
        "score = tf.model.evaluate(x_train, y_train)\n",
        "print('Accuracy: ', score[1])\n",
        "# loss: 0.2455 - accuracy: 0.9320"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: \n",
            " [[1.5518695e-09 7.1774146e-13 2.8524340e-07 ... 9.9985552e-01\n",
            "  7.7249114e-09 6.1956683e-07]\n",
            " [1.6148534e-11 8.7673911e-08 9.9999988e-01 ... 1.1998309e-18\n",
            "  7.3968009e-10 1.2654576e-18]\n",
            " [1.0639357e-06 9.9940383e-01 7.4963253e-05 ... 2.5830956e-04\n",
            "  2.0042752e-04 1.5897924e-06]\n",
            " ...\n",
            " [1.6069558e-17 6.6693204e-16 2.1484085e-18 ... 1.6443114e-09\n",
            "  5.9649103e-09 3.3973149e-06]\n",
            " [4.4134699e-13 4.3493293e-18 3.0589116e-17 ... 5.4483853e-15\n",
            "  8.0365731e-07 9.3915688e-18]\n",
            " [2.1201134e-13 2.3542765e-19 3.9084732e-13 ... 1.2530984e-17\n",
            "  4.5244418e-16 3.2563957e-17]]\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0063 - accuracy: 0.9984\n",
            "Accuracy:  0.9983833432197571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfvK8_e8Hq0K",
        "outputId": "b9cd823f-2fd0-4ff3-f0f5-8775d510d9f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# test 하는 함수\n",
        "random.seed(777)\n",
        "\n",
        "y_predicted = tf.model.predict(x_test)\n",
        "# x_test를 통해 미리 predict된 list 생성\n",
        "for x in range(0, 10):\n",
        "    random_index = random.randint(0, x_test.shape[0]-1)\n",
        "    # x_test의 크기 중 random index를 구한다.\n",
        "    \n",
        "    print(\"index: \", random_index,\n",
        "          \"actual y: \", np.argmax(y_test[random_index]),\n",
        "          \"predicted y: \", np.argmax(y_predicted[random_index]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index:  3757 actual y:  8 predicted y:  8\n",
            "index:  7304 actual y:  5 predicted y:  5\n",
            "index:  7300 actual y:  7 predicted y:  7\n",
            "index:  6039 actual y:  9 predicted y:  9\n",
            "index:  9429 actual y:  3 predicted y:  3\n",
            "index:  4420 actual y:  5 predicted y:  5\n",
            "index:  5507 actual y:  2 predicted y:  2\n",
            "index:  8809 actual y:  1 predicted y:  1\n",
            "index:  654 actual y:  5 predicted y:  5\n",
            "index:  7302 actual y:  8 predicted y:  8\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}